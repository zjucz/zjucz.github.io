[{"authors":null,"categories":null,"content":"Zheng Cao (曹政) is a Ph.D. candidate, majoring in computer science, Zhejiang University, under the supervision from Prof. Jian Wu. He is currently working as a research intern in Tencent Quantum Lab, cooperating with Prof. Tingjun Hou and Dr. Chang-Yu Hsieh. He is member of ZJU RealDoctor AI Research Centre and ZJU Innovative Drug Discovery Insitute. His research interests include AI for medical image analysis and AI for drug discovery.\nHere is my full [publications list](./publication/). --  Download my resumé. --   window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-7Q0V5Y3KXJ');  ","date":1647820800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1647820800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Zheng Cao (曹政) is a Ph.D. candidate, majoring in computer science, Zhejiang University, under the supervision from Prof. Jian Wu. He is currently working as a research","tags":null,"title":"Zheng Cao","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://zjucz.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Haihua Zhu","Haojie Yu","Fan Zhang","Zheng Cao","Fuli Wu","Fudong Zhu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1647820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647820800,"objectID":"b483c5f9dbe3196cdbe3278b50069bc3","permalink":"https://zjucz.github.io/publication/automatic-segmentation-and-detection-of-ectopic-eruption-of-the-first-permanent-molars-on-panoramic-radiographs-based-on-nnu-net/","publishdate":"2022-03-21T00:00:00Z","relpermalink":"/publication/automatic-segmentation-and-detection-of-ectopic-eruption-of-the-first-permanent-molars-on-panoramic-radiographs-based-on-nnu-net/","section":"publication","summary":"Periodontal Bone Loss assessment.","tags":["medical imaging"],"title":"Automatic Segmentation and Detection of Ectopic Eruption of the First Permanent Molars on Panoramic Radiographs Based on nnU‐Net","type":"publication"},{"authors":["Zheng Cao","Xiang Pan","Hongyun Yu","Shiyuan Hua","Da Wang","Danny Z. Chen","Min Zhou","Jian Wu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"17810488f50771be6d396c56a2c82094","permalink":"https://zjucz.github.io/publication/a-deep-learning-approach-for-detecting-colorectal-cancer-via-raman-spectra/","publishdate":"2022-05-02T00:00:00Z","relpermalink":"/publication/a-deep-learning-approach-for-detecting-colorectal-cancer-via-raman-spectra/","section":"publication","summary":"Colorectal Cancer Diagnosis via Raman Spectra.","tags":["medical imaging"],"title":"A Deep Learning Approach for Detecting Colorectal Cancer via Raman Spectra","type":"publication"},{"authors":["Haihua Zhu","Zheng Cao","Luya Lian","Guanchen Ye","Honghao Gao","Jian Wu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1641059940,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641059940,"objectID":"3a6c79a118a5e4a541f1467d28ad3247","permalink":"https://zjucz.github.io/publication/cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image/","publishdate":"2022-01-03T20:00:00Z","relpermalink":"/publication/cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image/","section":"publication","summary":"X-ray Segmentation of dental caries.","tags":["medical imaging"],"title":"CariesNet: A Deep learning Approach for Segmentation of multi-stage Caries lesion from Oral Panoramic X-Ray Image","type":"publication"},{"authors":["Linhong Jiang","Daqian Chen","Zheng Cao","Haihua Zhu","Fudong Zhu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"c8ce6f3c400a98b8b0d0399888845c5f","permalink":"https://zjucz.github.io/publication/a-two-stage-deep-learning-architecture-for-radiographic-assessment-of-periodontal-bone-loss/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/publication/a-two-stage-deep-learning-architecture-for-radiographic-assessment-of-periodontal-bone-loss/","section":"publication","summary":"Periodontal Bone Loss assessment.","tags":["medical imaging"],"title":"A Two-Stage Deep Learning Architecture for Radiographic Assessment of Periodontal Bone Loss","type":"publication"},{"authors":["Zheng Cao","Cailin Mu","Haochao Ying","Jian Wu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1626307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626307200,"objectID":"e014bc89f3d01c114a3dbe9f876fca3e","permalink":"https://zjucz.github.io/publication/full-scale-attention-for-automated-covid-19-diagnosis-from-ct-images/","publishdate":"2021-07-15T00:00:00Z","relpermalink":"/publication/full-scale-attention-for-automated-covid-19-diagnosis-from-ct-images/","section":"publication","summary":"Novel Attention-based Deep learning architecture for COVID-19 diagnose and lesion segmentation.","tags":["medical imaging"],"title":"Full Scale Attention for Automated COVID-19 Diagnosis from CT Images","type":"publication"},{"authors":null,"categories":null,"content":"Docking, Retrosynthesis, etc.\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"50db70ce71287f5d710b6dc18f77c391","permalink":"https://zjucz.github.io/project/drug-discovery/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/project/drug-discovery/","section":"project","summary":"Retrosynthesis","tags":["Deep Learning"],"title":"Drug Discovery","type":"project"},{"authors":["Zheng Cao"],"categories":["deep learning"],"content":"Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation.\nAlthough uuUNet is easy to ulitize in 3D segmentation tasks, it\u0026rsquo;s difficult to train a personal dataset with 2d images. The preparation of dataset should follow strict guidelines.\nMethods Step1. Prepare Envs Create vitual environment in conda:\nconda create -n nnunet python=3.8  Prepare datafloders.\nDATASET/nnUNet_raw_data/Task002_Heart ├── nnUNet_preprocessed ├── nnUNet_trained_models ├── nnUNet_raw │ ├── nnUNet_croped_data │ ├── nnUNet_raw_data  Step2. Covert Data Following guidance here.\n How to use 2D data with nnU-Net nnU-Net was originally built for 3D images. It is also strongestwhen applied to 3D segmentation problems because a large proportion of itsdesign choices were built with 3D in mind. Also note that many 2D segmentationproblems, especially in the non-biomedical domain, may benefit from pretrainednetwork architectures which nnU-Net does not support. Still, there is certainlya need for an out of the box segmentation solution for 2D segmentationproblems. And also on 2D segmentation tasks nnU-Net cam perform extremely well!We have, for example, won a 2D task in the cell tracking challenge with nnU-Net(see our Nature Methods paper) and we have also successfully applied nnU-Net tohistopathological segmentation problems. Working with 2D data in nnU-Netrequires a small workaround in the creation of the dataset. Essentially, allimages must be converted to pseudo 3D images (so an image with shape (X, Y)needs to be converted to an image with shape (1, X, Y). The resulting imagemust be saved in nifti format. Hereby it is important to set the spacing of thefirst axis (the one with shape 1) to a value larger than the others. If you areworking with niftis anyways, then doing this should be easy for you. Thisexample here is intended for demonstrating how nnU-Net can be used with’regular’ 2D images. We selected the massachusetts road segmentation datasetfor this because it can be obtained easily, it comes with a good amount oftraining cases but is still not too large to be difficult to handle.\n Here is my converting code:\nimport numpy as np from batchgenerators.utilities.file_and_folder_operations import * from nnunet.dataset_conversion.utils import generate_dataset_json from nnunet.paths import nnUNet_raw_data, preprocessing_output_dir from nnunet.utilities.file_conversions import convert_2d_image_to_nifti imgs = '/data/caozheng/*' masks = '/data/caozheng/*' root = 'DATASET/imagesTr' label_root = 'DATASET/labelsTr' for i in os.listdir(imgs): img = os.path.join(imgs, i) convert_2d_image_to_nifti(img, os.path.join(root, i.split('.')[0]), is_seg=False) print('Finish：'+ i ) for i in os.listdir(masks): mask = os.path.join(masks, i) convert_2d_image_to_nifti(mask, os.path.join(label_root, i.split('.')[0]), is_seg=True, transform=lambda x: (x \u0026gt; 0).astype(int)) # transform=lambda x: (x \u0026gt; 0).astype(int) depends on label mode. print('Finish：'+ i )  Then generate dataset.json file, which can be mantually created or created by default code.\ngenerate_dataset_json(os.path.join(raw, 'dataset.json'), os.path.join(raw, 'imagesTr'), os.path.join(raw, 'imagesTs'), ('background', 'caries'), {'background':0, 'caries':1}, 'caries_dataset', dataset_description='Private Test!', dataset_release='0.0.1')  Step3. Move Data to suitable position The data format of nnUnet is fixed. Task002_Heart is composed of Task ID data name, imagesTr is training data, imagesTs is test data, labelsTr is the label of training data, data sample la_003_0000.nii.gz is marked by case sample name modal.nii. It is composed of gz. Different modals are distinguished by 0000/0001/0002/0003. I set the new task ID to 100.\nDATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart ├── dataset.json ├── imagesTr │ ├── la_003_0000.nii.gz │ ├── la_004_0000.nii.gz │ ├── ... ├── imagesTs │ ├── la_001_0000.nii.gz │ ├── la_002_0000.nii.gz │ ├── ... └── labelsTr ├── la_003.nii.gz ├── la_004.nii.gz ├── ...  Our original 2-dimensional data is RGB three-channel, we can regard the RGB three-channel data as three modalities, extract the data of different channels separately, convert the shape to (1, width, height), and save it as 3 with SimpleITK Dimensional data.\nStep4. Install Packages Download nnunet code:\nconda activate nnunet  git clone https://github.com/MIC-DKFZ/nnUNet.git  and install it.\npip install -e .  Then set a environment variable\nexport nnUNet_raw_data_base=\u0026quot;/data/Project/nnUnet/Data/nnUNet_raw\u0026quot; export nnUNet_preprocessed=\u0026quot;/data/Project/nnUnet/Data/nnUNet_preprocessed\u0026quot; export RESULTS_FOLDER=\u0026quot;/data/Project/nnUnet/Data/nnUNet_trained_models\u0026quot;  Step5. Pre-process and Training Pre-process will create large amount of data.\nnnUNet_plan_and_preprocess -t 2  Here 2 is the task id, which is identified in folder DATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart\nNow it\u0026rsquo;s prepared for training! Here we use 5-fold traning, \u0026ndash;npz means create softmax prediction.\nCUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 0 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 1 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 2 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 3 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 4 --npz  ","date":1618012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618012800,"objectID":"012fc3b26f56f9218f6d6e7acbced9e2","permalink":"https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/","publishdate":"2021-04-10T00:00:00Z","relpermalink":"/post/training-2d-nnunet-with-personal-dataset/","section":"post","summary":"Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation.","tags":["deep learning","image segmentation"],"title":"Training 2D nnUNet with personal dataset","type":"post"},{"authors":null,"categories":null,"content":"MedIA is a wide subject, including different image modalities, i.e. CT/MRI/X-ray.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"a40cce3bc3f23eac7c025f6580d44fa7","permalink":"https://zjucz.github.io/project/medical-image-analysis/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/medical-image-analysis/","section":"project","summary":"To be finisehed","tags":["Deep Learning"],"title":"Medical Image Analysis","type":"project"},{"authors":["Zheng Cao","Chuanbin Sun","Wenzhe Wang","Xiangshang Zheng","Jian Wu","Honghao Gao"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591315200,"objectID":"f71b509a49bae9030a2f7cae1df51e04","permalink":"https://zjucz.github.io/publication/multi-modality-fusion-learning-for-the-automatic-diagnosis-of-optic-neuropathy/","publishdate":"2020-12-30T00:00:00Z","relpermalink":"/publication/multi-modality-fusion-learning-for-the-automatic-diagnosis-of-optic-neuropathy/","section":"publication","summary":"Multi-modality model for optic neuropathy diagnose.","tags":["medical imaging"],"title":"Multi-modality fusion learning for the automatic diagnosis of optic neuropathy","type":"publication"},{"authors":["Zheng Cao","Bohan Yu","Biwen Lei","Haochao Ying","Xiao Zhang","Danny Z. Chen","Jian Wu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"010d24e3ef82bc1a644e5c1121817dd2","permalink":"https://zjucz.github.io/publication/cascaded-se-resunet-for-segmentation-of-thoracic-organs-at-risk/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/publication/cascaded-se-resunet-for-segmentation-of-thoracic-organs-at-risk/","section":"publication","summary":"CT Segmentation of five thoracic organs.","tags":["medical imaging"],"title":"Cascaded SE-ResUnet for segmentation of thoracic organs at risk","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-635479821', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$  renders as\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\n1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% callout note %}} ... {{% /callout %}}, it will render as an aside.\n{{% callout note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /callout %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}}  renders as\nClick to view the spoiler You found me!\n Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://zjucz.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Zheng Cao"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://zjucz.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://zjucz.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zjucz.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]
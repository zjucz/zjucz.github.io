<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.1.0 for Hugo"><meta name=author content="Zheng Cao"><meta name=description content="Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation."><link rel=alternate hreflang=en-us href=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'"><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'"><link rel=stylesheet href=/css/wowchemy.18dd1b2d2475654c7c0c47d29f638859.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hu11361c0288a87fbf93fc0f06f84edd26_64780_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu11361c0288a87fbf93fc0f06f84edd26_64780_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@caozhengzju"><meta property="twitter:creator" content="@caozhengzju"><meta property="og:site_name" content="Z.Cao"><meta property="og:url" content="https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/"><meta property="og:title" content="Training 2D nnUNet with personal dataset | Z.Cao"><meta property="og:description" content="Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation."><meta property="og:image" content="https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/featured.jpg"><meta property="twitter:image" content="https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2021-04-10T00:00:00+00:00"><meta property="article:modified_time" content="2021-04-10T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/"},"headline":"Training 2D nnUNet with personal dataset","image":["https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/featured.jpg"],"datePublished":"2021-04-10T00:00:00Z","dateModified":"2021-04-10T00:00:00Z","author":{"@type":"Person","name":"Zheng Cao"},"publisher":{"@type":"Organization","name":"Zhejiang University","logo":{"@type":"ImageObject","url":"https://zjucz.github.io/media/icon_hu11361c0288a87fbf93fc0f06f84edd26_64780_192x192_fill_lanczos_center_2.png"}},"description":"Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation."}</script><title>Training 2D nnUNet with personal dataset | Z.Cao</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=012fc3b26f56f9218f6d6e7acbced9e2><script src=/js/wowchemy-init.min.f16be01fc8fb2b5885dd67ce942d1185.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Z.Cao</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Z.Cao</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#skills><span>Skills</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#awards><span>Awards</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Training 2D nnUNet with personal dataset</h1><div class=article-metadata><div><span class=author-highlighted>Zheng Cao</span></div><span class=article-date>Apr 10, 2021</span>
<span class=middot-divider></span><span class=article-reading-time>4 min read</span>
<span class=middot-divider></span><span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>deep learning</a></span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/project/medical-image-analysis/>Project</a></div></div><div class="article-header container-fluid featured-image-wrapper mt-4 mb-4" style=max-width:1101px;max-height:300px><div style=position:relative><img src=/post/training-2d-nnunet-with-personal-dataset/featured.jpg alt class=featured-image>
<span class=article-header-caption>Image credit: <a href=https://unsplash.com/photos/OGZtQF8iC0g><strong>John Moeses Bauan</strong></a></span></div></div><div class=article-container><div class=article-style><h2 id=introduction>Introduction</h2><p>nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper <a href=https://www.nature.com/articles/s41592-020-01008-z target=_blank rel=noopener>Automated Design of Deep Learning Methods for Biomedical Image Segmentation</a>.</p><p><img src=./arch.png alt=png></p><p>Although uuUNet is easy to ulitize in 3D segmentation tasks, it&rsquo;s difficult to train a personal dataset with 2d images. The preparation of dataset should follow strict guidelines.</p><h2 id=methods>Methods</h2><h4 id=step1-prepare-envs>Step1. Prepare Envs</h4><p>Create vitual environment in conda:</p><pre><code class=language-python>conda create -n nnunet python=3.8
</code></pre><p>Prepare datafloders.</p><pre><code>DATASET/nnUNet_raw_data/Task002_Heart
├── nnUNet_preprocessed
├── nnUNet_trained_models
├── nnUNet_raw
│   ├── nnUNet_croped_data
│   ├── nnUNet_raw_data
</code></pre><h4 id=step2-covert-data>Step2. Covert Data</h4><p>Following guidance here.</p><blockquote><p>How to use 2D data with nnU-Net
nnU-Net was originally built for 3D images. It is also strongestwhen applied to 3D segmentation problems because a large proportion of itsdesign choices were built with 3D in mind. Also note that many 2D segmentationproblems, especially in the non-biomedical domain, may benefit from pretrainednetwork architectures which nnU-Net does not support. Still, there is certainlya need for an out of the box segmentation solution for 2D segmentationproblems. And also on 2D segmentation tasks nnU-Net cam perform extremely well!We have, for example, won a 2D task in the cell tracking challenge with nnU-Net(see our Nature Methods paper) and we have also successfully applied nnU-Net tohistopathological segmentation problems. Working with 2D data in nnU-Netrequires a small workaround in the creation of the dataset. Essentially, allimages must be converted to pseudo 3D images (so an image with shape (X, Y)needs to be converted to an image with shape (1, X, Y). The resulting imagemust be saved in nifti format. Hereby it is important to set the spacing of thefirst axis (the one with shape 1) to a value larger than the others. If you areworking with niftis anyways, then doing this should be easy for you. Thisexample here is intended for demonstrating how nnU-Net can be used with’regular’ 2D images. We selected the massachusetts road segmentation datasetfor this because it can be obtained easily, it comes with a good amount oftraining cases but is still not too large to be difficult to handle.</p></blockquote><p>Here is my converting code:</p><pre><code class=language-python>import numpy as np
from batchgenerators.utilities.file_and_folder_operations import *
from nnunet.dataset_conversion.utils import generate_dataset_json
from nnunet.paths import nnUNet_raw_data, preprocessing_output_dir
from nnunet.utilities.file_conversions import convert_2d_image_to_nifti
imgs = '/data/caozheng/*'
masks = '/data/caozheng/*'
root = 'DATASET/imagesTr'
label_root = 'DATASET/labelsTr'

for i in os.listdir(imgs):
    img = os.path.join(imgs, i)
    convert_2d_image_to_nifti(img, os.path.join(root, i.split('.')[0]), is_seg=False)
    print('Finish：'+ i )

for i in os.listdir(masks):
    mask = os.path.join(masks, i)
    convert_2d_image_to_nifti(mask, os.path.join(label_root, i.split('.')[0]), is_seg=True,
                             transform=lambda x: (x &gt; 0).astype(int))
    # transform=lambda x: (x &gt; 0).astype(int) depends on label mode.
    print('Finish：'+ i )
</code></pre><p>Then generate dataset.json file, which can be mantually created or created by default code.</p><pre><code class=language-python>generate_dataset_json(os.path.join(raw, 'dataset.json'), os.path.join(raw, 'imagesTr'),  os.path.join(raw, 'imagesTs'), ('background', 'caries'), {'background':0, 'caries':1}, 'caries_dataset', dataset_description='Private Test!', dataset_release='0.0.1')
</code></pre><h4 id=step3-move-data-to-suitable-position>Step3. Move Data to suitable position</h4><p>The data format of nnUnet is fixed. Task002_Heart is composed of Task ID data name, imagesTr is training data, imagesTs is test data, labelsTr is the label of training data, data sample la_003_0000.nii.gz is marked by case sample name modal.nii. It is composed of gz. Different modals are distinguished by 0000/0001/0002/0003. I set the new task ID to 100.</p><pre><code>DATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart
├── dataset.json
├── imagesTr
│   ├── la_003_0000.nii.gz
│   ├── la_004_0000.nii.gz
│   ├── ...
├── imagesTs
│   ├── la_001_0000.nii.gz
│   ├── la_002_0000.nii.gz
│   ├── ...
└── labelsTr
    ├── la_003.nii.gz
    ├── la_004.nii.gz
    ├── ...
</code></pre><p>Our original 2-dimensional data is RGB three-channel, we can regard the RGB three-channel data as three modalities, extract the data of different channels separately, convert the shape to (1, width, height), and save it as 3 with SimpleITK Dimensional data.</p><h4 id=step4-install-packages>Step4. Install Packages</h4><p>Download nnunet code:</p><pre><code class=language-bash>conda activate nnunet
</code></pre><pre><code class=language-bash>git clone https://github.com/MIC-DKFZ/nnUNet.git
</code></pre><p>and install it.</p><pre><code class=language-bash>pip install -e .
</code></pre><p>Then set a environment variable</p><pre><code class=language-cpp>export nnUNet_raw_data_base=&quot;/data/Project/nnUnet/Data/nnUNet_raw&quot;
export nnUNet_preprocessed=&quot;/data/Project/nnUnet/Data/nnUNet_preprocessed&quot;
export RESULTS_FOLDER=&quot;/data/Project/nnUnet/Data/nnUNet_trained_models&quot;
</code></pre><h4 id=step5-pre-process-and-training>Step5. Pre-process and Training</h4><p>Pre-process will create large amount of data.</p><pre><code class=language-bash>nnUNet_plan_and_preprocess -t 2
</code></pre><p>Here 2 is the task id, which is identified in folder <em>DATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart</em></p><p>Now it&rsquo;s prepared for training! Here we use 5-fold traning, &ndash;npz means create softmax prediction.</p><pre><code class=language-bash>CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 0  --npz
CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 1  --npz
CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 2  --npz
CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 3  --npz
CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 4  --npz
</code></pre></div><div class=article-tags><a class="badge badge-light" href=/tag/deep-learning/>deep learning</a>
<a class="badge badge-light" href=/tag/image-segmentation/>image segmentation</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/&text=Training%202D%20nnUNet%20with%20personal%20dataset" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/&t=Training%202D%20nnUNet%20with%20personal%20dataset" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Training%202D%20nnUNet%20with%20personal%20dataset&body=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/&title=Training%202D%20nnUNet%20with%20personal%20dataset" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Training%202D%20nnUNet%20with%20personal%20dataset%20https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://zjucz.github.io/post/training-2d-nnunet-with-personal-dataset/&title=Training%202D%20nnUNet%20with%20personal%20dataset" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://zjucz.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hu11dccbb851f6c033b62b7ccdc6c8a6b9_1108456_270x270_fill_q75_lanczos_center.jpg alt="Zheng Cao"></a><div class=media-body><h5 class=card-title><a href=https://zjucz.github.io/>Zheng Cao</a></h5><h6 class=card-subtitle>Ph.D. Candidate</h6><p class=card-text>Stay hungry, Stay foolish.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:z.cao@zju.edu.cn><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/caozhengzju target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=lBrfv0EAAAAJ&hl=zh-CN" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/nuistcz target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href="https://www.linkedin.com/in/%e6%94%bf-%e6%9b%b9-2367a9147/?locale=en_US" target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/project/drug-discovery/>Drug Discovery</a></li><li><a href=/project/medical-image-analysis/>Medical Image Analysis</a></li></ul></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>浙ICP备2021027422号-1 Copyright@2022 Zheng Cao</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin=anonymous title=mermaid></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.ad299157ffff5f8e3caf9b0eff697052.js></script></body></html>